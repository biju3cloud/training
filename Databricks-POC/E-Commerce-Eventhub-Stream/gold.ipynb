{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d201f087-6e99-4ff1-b998-41153c3a5084",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ./config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "83182df3-a5b3-430e-8776-bc84ea4147ff",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1765855533390}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      },
      "1": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1765855533398}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 1
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Databricks notebook source\n",
    "# MAGIC %md\n",
    "# MAGIC # Gold Layer - Streaming Business Aggregations\n",
    "# MAGIC Creates real-time aggregated metrics tables for business intelligence\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# MAGIC %md\n",
    "# MAGIC ## Configuration\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"GOLD LAYER STREAMING CONFIGURATION\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Source: {silver_table}\")\n",
    "print(f\"\\nGold Tables:\")\n",
    "print(f\"  1. {gold_brand_category_table}\")\n",
    "print(f\"  2. {gold_location_table}\")\n",
    "print(f\"  3. {gold_product_table}\")\n",
    "print(f\"  4. {gold_customer_table}\")\n",
    "print(f\"  5. {gold_daily_summary_table}\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# MAGIC %md\n",
    "# MAGIC ## Read Silver Stream\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"READING SILVER STREAM\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Read streaming data from Silver with watermark\n",
    "silver_stream = (spark.readStream\n",
    "    .format(\"delta\")\n",
    "    .table(silver_table)\n",
    "    .withWatermark(\"silver_timestamp\", \"10 minutes\")  # Handle late data up to 10 minutes\n",
    ")\n",
    "\n",
    "print(f\"‚úì Silver stream configured\")\n",
    "print(f\"  Source: {silver_table}\")\n",
    "print(f\"  Watermark: 10 minutes on silver_timestamp\")\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# MAGIC %md\n",
    "# MAGIC ## Gold Stream 1: Sales by Brand and Category\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STARTING: Sales by Brand and Category Stream\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Aggregate by brand and category\n",
    "# Aggregate by brand and category\n",
    "sales_by_brand_category_stream = (\n",
    "    silver_stream\n",
    "    .groupBy(\"brand\", \"category\")\n",
    "    .agg(\n",
    "        count(\"*\").alias(\"order_count\"),\n",
    "        sum(\"quantity\").alias(\"total_quantity\"),\n",
    "        sum(\"total_amount\").alias(\"total_revenue\"),\n",
    "        avg(\"total_amount\").alias(\"avg_order_value\"),\n",
    "        min(\"total_amount\").alias(\"min_order_value\"),\n",
    "        max(\"total_amount\").alias(\"max_order_value\"),\n",
    "        approx_count_distinct(\"customer_id\").alias(\"unique_customers\"),\n",
    "        # approx_count_distinct(\"product_id\").alias(\"unique_products\"),  # Uncomment if needed\n",
    "        sum(\"discount_amount\").alias(\"total_discounts\")\n",
    "    )\n",
    "    .select(\n",
    "        \"brand\",\n",
    "        \"category\",\n",
    "        \"order_count\",\n",
    "        \"total_quantity\",\n",
    "        round(col(\"total_revenue\"), 2).alias(\"total_revenue\"),\n",
    "        round(col(\"avg_order_value\"), 2).alias(\"avg_order_value\"),\n",
    "        round(col(\"min_order_value\"), 2).alias(\"min_order_value\"),\n",
    "        round(col(\"max_order_value\"), 2).alias(\"max_order_value\"),\n",
    "        \"unique_customers\",\n",
    "        # \"unique_products\",\n",
    "        round(col(\"total_discounts\"), 2).alias(\"total_discounts\"),\n",
    "        current_timestamp().alias(\"gold_timestamp\")\n",
    "    )\n",
    ")\n",
    "\n",
    "# Write stream\n",
    "brand_category_query = (sales_by_brand_category_stream\n",
    "    .writeStream\n",
    "    .format(\"delta\")\n",
    "    .outputMode(\"complete\")  # Complete mode for full aggregations\n",
    "    .option(\"checkpointLocation\", gold_brand_checkpoint)\n",
    "    .option(\"mergeSchema\", \"true\")\n",
    "    #.trigger(processingTime=\"20 seconds\")\n",
    "    .trigger(once=True) # for testing\n",
    "    .toTable(gold_brand_category_table)\n",
    ")\n",
    "\n",
    "print(f\"‚úì Brand/Category stream started\")\n",
    "print(f\"  Query ID: {brand_category_query.id}\")\n",
    "print(f\"  Target: {gold_brand_category_table}\")\n",
    "print(f\"  Output Mode: complete\")\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# MAGIC %md\n",
    "# MAGIC ## Gold Stream 2: Location Performance\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STARTING: Location Performance Stream\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Aggregate by location\n",
    "location_performance_stream = (\n",
    "    silver_stream\n",
    "    .groupBy(\"location\")\n",
    "    .agg(\n",
    "        count(\"*\").alias(\"order_count\"),\n",
    "        sum(\"total_amount\").alias(\"total_revenue\"),\n",
    "        avg(\"total_amount\").alias(\"avg_order_value\"),\n",
    "        sum(\"quantity\").alias(\"total_items_sold\"),\n",
    "        approx_count_distinct(\"customer_id\").alias(\"unique_customers\"),\n",
    "        approx_count_distinct(\"product_name\").alias(\"unique_products\"),\n",
    "        approx_count_distinct(\"brand\").alias(\"unique_brands\"),\n",
    "        sum(when(col(\"order_status\") == \"delivered\", 1).otherwise(0)).alias(\"delivered_orders\"),\n",
    "        sum(when(col(\"order_status\") == \"pending\", 1).otherwise(0)).alias(\"pending_orders\")\n",
    "    )\n",
    "    .select(\n",
    "        \"location\",\n",
    "        \"order_count\",\n",
    "        round(col(\"total_revenue\"), 2).alias(\"total_revenue\"),\n",
    "        round(col(\"avg_order_value\"), 2).alias(\"avg_order_value\"),\n",
    "        \"total_items_sold\",\n",
    "        \"unique_customers\",\n",
    "        \"unique_products\",\n",
    "        \"unique_brands\",\n",
    "        \"delivered_orders\",\n",
    "        \"pending_orders\",\n",
    "        round((col(\"delivered_orders\") / col(\"order_count\") * 100), 2).alias(\"delivery_rate_pct\"),\n",
    "        current_timestamp().alias(\"gold_timestamp\")\n",
    "    )\n",
    ")\n",
    "\n",
    "# Write stream\n",
    "location_query = (location_performance_stream\n",
    "    .writeStream\n",
    "    .format(\"delta\")\n",
    "    .outputMode(\"complete\")\n",
    "    .option(\"checkpointLocation\", gold_location_checkpoint)\n",
    "    .option(\"mergeSchema\", \"true\")\n",
    "   # .trigger(processingTime=\"20 seconds\")\n",
    "    .trigger(once=True) # for testing\n",
    "    .toTable(gold_location_table)\n",
    ")\n",
    "\n",
    "print(f\"‚úì Location performance stream started\")\n",
    "print(f\"  Query ID: {location_query.id}\")\n",
    "print(f\"  Target: {gold_location_table}\")\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# MAGIC %md\n",
    "# MAGIC ## Gold Stream 3: Product Performance\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STARTING: Product Performance Stream\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Aggregate by product\n",
    "# Aggregate by product (remove product_id)\n",
    "product_performance_stream = (\n",
    "    silver_stream\n",
    "    .groupBy(\"product_name\", \"brand\", \"category\", \"base_price\")\n",
    "    .agg(\n",
    "        count(\"*\").alias(\"order_count\"),\n",
    "        sum(\"quantity\").alias(\"total_quantity_sold\"),\n",
    "        sum(\"total_amount\").alias(\"total_revenue\"),\n",
    "        avg(\"unit_price\").alias(\"avg_selling_price\"),\n",
    "        min(\"unit_price\").alias(\"min_selling_price\"),\n",
    "        max(\"unit_price\").alias(\"max_selling_price\"),\n",
    "        approx_count_distinct(\"customer_id\").alias(\"unique_customers\"),\n",
    "        approx_count_distinct(\"location\").alias(\"locations_sold\"),\n",
    "        avg(\"discount_pct\").alias(\"avg_discount_pct\"),\n",
    "        sum(\"discount_amount\").alias(\"total_discount_amount\")\n",
    "    )\n",
    "    .select(\n",
    "        \"product_name\",\n",
    "        \"brand\",\n",
    "        \"category\",\n",
    "        \"base_price\",\n",
    "        \"order_count\",\n",
    "        \"total_quantity_sold\",\n",
    "        round(col(\"total_revenue\"), 2).alias(\"total_revenue\"),\n",
    "        round(col(\"avg_selling_price\"), 2).alias(\"avg_selling_price\"),\n",
    "        round(col(\"min_selling_price\"), 2).alias(\"min_selling_price\"),\n",
    "        round(col(\"max_selling_price\"), 2).alias(\"max_selling_price\"),\n",
    "        \"unique_customers\",\n",
    "        \"locations_sold\",\n",
    "        round(col(\"avg_discount_pct\") * 100, 2).alias(\"avg_discount_pct\"),\n",
    "        round(col(\"total_discount_amount\"), 2).alias(\"total_discount_amount\"),\n",
    "        round((col(\"total_revenue\") / col(\"total_quantity_sold\")), 2).alias(\"revenue_per_unit\"),\n",
    "        current_timestamp().alias(\"gold_timestamp\")\n",
    "    )\n",
    ")\n",
    "\n",
    "# Write stream\n",
    "product_query = (product_performance_stream\n",
    "    .writeStream\n",
    "    .format(\"delta\")\n",
    "    .outputMode(\"complete\")\n",
    "    .option(\"checkpointLocation\", gold_product_checkpoint)\n",
    "    .option(\"mergeSchema\", \"true\")\n",
    "    #.trigger(processingTime=\"20 seconds\")\n",
    "    .trigger(once=True) # for testing\n",
    "    .toTable(gold_product_table)\n",
    ")\n",
    "\n",
    "print(f\"‚úì Product performance stream started\")\n",
    "print(f\"  Query ID: {product_query.id}\")\n",
    "print(f\"  Target: {gold_product_table}\")\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# MAGIC %md\n",
    "# MAGIC ## Gold Stream 4: Customer Insights (Using foreachBatch)\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "customer_insights_stream = (\n",
    "    silver_stream\n",
    "    .filter(\n",
    "        col(\"customer_id\").isNotNull() & \n",
    "        col(\"order_timestamp\").isNotNull()\n",
    "    )\n",
    "    .groupBy(\"customer_id\", \"customer_name\", \"location\")\n",
    "    .agg(\n",
    "        count(\"*\").alias(\"order_count\"),\n",
    "        sum(\"total_amount\").alias(\"total_spent\"),\n",
    "        avg(\"total_amount\").alias(\"avg_order_value\"),\n",
    "        sum(\"quantity\").alias(\"total_items_purchased\"),\n",
    "        min(\"order_timestamp\").alias(\"first_order_date\"),\n",
    "        max(\"order_timestamp\").alias(\"last_order_date\"),\n",
    "        approx_count_distinct(\"product_name\").alias(\"unique_products_bought\"),\n",
    "        approx_count_distinct(\"brand\").alias(\"unique_brands\"),\n",
    "        approx_count_distinct(\"category\").alias(\"unique_categories\"),\n",
    "        avg(coalesce(col(\"discount_pct\"), lit(0))).alias(\"avg_discount_rate\")\n",
    "    )\n",
    "    .withColumn(\n",
    "        \"days_as_customer\", \n",
    "        when(\n",
    "            col(\"first_order_date\").isNotNull() & col(\"last_order_date\").isNotNull(),\n",
    "            datediff(col(\"last_order_date\"), col(\"first_order_date\"))\n",
    "        ).otherwise(0)\n",
    "    )\n",
    "    .withColumn(\n",
    "        \"customer_segment\",\n",
    "        when(col(\"total_spent\") >= 5000, \"High Value\")\n",
    "        .when(col(\"total_spent\") >= 2000, \"Medium Value\")\n",
    "        .otherwise(\"Low Value\")\n",
    "    )\n",
    "    .select(\n",
    "        \"customer_id\",\n",
    "        \"customer_name\",\n",
    "        \"location\",\n",
    "        \"order_count\",\n",
    "        round(col(\"total_spent\"), 2).alias(\"total_spent\"),\n",
    "        round(col(\"avg_order_value\"), 2).alias(\"avg_order_value\"),\n",
    "        \"total_items_purchased\",\n",
    "        \"first_order_date\",\n",
    "        \"last_order_date\",\n",
    "        \"days_as_customer\",\n",
    "        \"unique_products_bought\",\n",
    "        \"unique_brands\",\n",
    "        \"unique_categories\",\n",
    "        round(col(\"avg_discount_rate\") * 100, 2).alias(\"avg_discount_pct\"),\n",
    "        \"customer_segment\",\n",
    "        current_timestamp().alias(\"gold_timestamp\")\n",
    "    )\n",
    ")\n",
    "# Write with complete mode (simpler, no MERGE needed)\n",
    "customer_query = (customer_insights_stream\n",
    "    .writeStream\n",
    "    .format(\"delta\")\n",
    "    .outputMode(\"complete\")\n",
    "    .option(\"checkpointLocation\", gold_customer_checkpoint)\n",
    "    .option(\"mergeSchema\", \"true\")\n",
    "   # .trigger(processingTime=\"30 seconds\")\n",
    "    .trigger(once=True) # for testing\n",
    "    .toTable(gold_customer_table)\n",
    ")\n",
    "\n",
    "print(f\"‚úì Customer insights stream started (simplified)\")\n",
    "print(f\"  Query ID: {customer_query.id}\")\n",
    "print(f\"  Target: {gold_customer_table}\")\n",
    "print(f\"  Output Mode: complete\")\n",
    "print(f\"  Note: Using countDistinct instead of collect_set for better stability\")\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# MAGIC %md\n",
    "# MAGIC ## Gold Stream 5: Daily Summary with Time Windows\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STARTING: Daily Summary Stream\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Windowed aggregations by day\n",
    "# Windowed aggregations by day\n",
    "daily_summary_stream = (\n",
    "    silver_stream\n",
    "    .withWatermark(\"order_timestamp\", \"1 hour\")\n",
    "    .groupBy(\n",
    "        window(col(\"order_timestamp\"), \"1 day\").alias(\"day_window\"),\n",
    "        \"location\",\n",
    "        \"category\"\n",
    "    )\n",
    "    .agg(\n",
    "        count(\"*\").alias(\"order_count\"),\n",
    "        sum(\"total_amount\").alias(\"daily_revenue\"),\n",
    "        avg(\"total_amount\").alias(\"avg_order_value\"),\n",
    "        sum(\"quantity\").alias(\"items_sold\"),\n",
    "        approx_count_distinct(\"customer_id\").alias(\"unique_customers\"),\n",
    "        approx_count_distinct(\"product_name\").alias(\"unique_products\"),\n",
    "        max(\"total_amount\").alias(\"highest_order\"),\n",
    "        min(\"total_amount\").alias(\"lowest_order\")\n",
    "    )\n",
    "    .select(\n",
    "        col(\"day_window.start\").alias(\"day\"),\n",
    "        \"location\",\n",
    "        \"category\",\n",
    "        \"order_count\",\n",
    "        round(col(\"daily_revenue\"), 2).alias(\"daily_revenue\"),\n",
    "        round(col(\"avg_order_value\"), 2).alias(\"avg_order_value\"),\n",
    "        \"items_sold\",\n",
    "        \"unique_customers\",\n",
    "        \"unique_products\",\n",
    "        round(col(\"highest_order\"), 2).alias(\"highest_order\"),\n",
    "        round(col(\"lowest_order\"), 2).alias(\"lowest_order\"),\n",
    "        current_timestamp().alias(\"gold_timestamp\")\n",
    "    )\n",
    ")\n",
    "\n",
    "# Write stream\n",
    "daily_query = (daily_summary_stream\n",
    "    .writeStream\n",
    "    .format(\"delta\")\n",
    "    .outputMode(\"append\")  # Append mode for windowed aggregations\n",
    "    .option(\"checkpointLocation\", gold_daily_checkpoint)\n",
    "    .option(\"mergeSchema\", \"true\")\n",
    "    #.trigger(processingTime=\"30 seconds\")\n",
    "    .trigger(once=True) # for testing\n",
    "    .toTable(gold_daily_summary_table)\n",
    ")\n",
    "\n",
    "print(f\"‚úì Daily summary stream started\")\n",
    "print(f\"  Query ID: {daily_query.id}\")\n",
    "print(f\"  Target: {gold_daily_summary_table}\")\n",
    "print(f\"  Window: 1 day\")\n",
    "print(f\"  Output Mode: append\")\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# MAGIC %md\n",
    "# MAGIC ## Monitor All Streaming Queries\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ACTIVE GOLD LAYER STREAMS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for stream in spark.streams.active:\n",
    "    print(f\"\\nQuery ID: {stream.id}\")\n",
    "    print(f\"  Name: {stream.name if stream.name else 'unnamed'}\")\n",
    "    print(f\"  Status: {stream.status['message']}\")\n",
    "    print(f\"  Is Active: {stream.isActive}\")\n",
    "    \n",
    "    if stream.recentProgress:\n",
    "        latest = stream.recentProgress[-1]\n",
    "        print(f\"  Recent Progress:\")\n",
    "        print(f\"    - Batch: {latest.get('batchId', 'N/A')}\")\n",
    "        print(f\"    - Input Rows: {latest.get('numInputRows', 0)}\")\n",
    "        print(f\"    - Processing Rate: {latest.get('processedRowsPerSecond', 0):.2f} rows/sec\")\n",
    "\n",
    "print(f\"\\nTotal Active Streams: {len(spark.streams.active)}\")\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# MAGIC %md\n",
    "# MAGIC ## Wait and Monitor (Run for 60 seconds)\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "import time\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"MONITORING GOLD STREAMS FOR 60 SECONDS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for i in range(12):\n",
    "    time.sleep(5)\n",
    "    print(f\"\\n‚è±Ô∏è  {(i+1)*5} seconds:\")\n",
    "    \n",
    "    # Check each gold table\n",
    "    try:\n",
    "        brand_count = spark.table(gold_brand_category_table).count()\n",
    "        print(f\"    Brand/Category: {brand_count} records\")\n",
    "    except:\n",
    "        print(f\"    Brand/Category: Not created yet\")\n",
    "    \n",
    "    try:\n",
    "        location_count = spark.table(gold_location_table).count()\n",
    "        print(f\"    Locations: {location_count} records\")\n",
    "    except:\n",
    "        print(f\"    Locations: Not created yet\")\n",
    "    \n",
    "    try:\n",
    "        product_count = spark.table(gold_product_table).count()\n",
    "        print(f\"    Products: {product_count} records\")\n",
    "    except:\n",
    "        print(f\"    Products: Not created yet\")\n",
    "    \n",
    "    try:\n",
    "        customer_count = spark.table(gold_customer_table).count()\n",
    "        print(f\"    Customers: {customer_count} records\")\n",
    "    except:\n",
    "        print(f\"    Customers: Not created yet\")\n",
    "    \n",
    "    try:\n",
    "        daily_count = spark.table(gold_daily_summary_table).count()\n",
    "        print(f\"    Daily Summary: {daily_count} records\")\n",
    "    except:\n",
    "        print(f\"    Daily Summary: Not created yet\")\n",
    "\n",
    "print(\"\\n‚úì Monitoring complete\")\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# MAGIC %md\n",
    "# MAGIC ## Verify Gold Tables\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"GOLD LAYER VERIFICATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# 1. Brand/Category\n",
    "try:\n",
    "    brand_cat_df = spark.table(gold_brand_category_table)\n",
    "    print(f\"\\n1. Sales by Brand/Category: {brand_cat_df.count()} records\")\n",
    "    display(brand_cat_df.orderBy(desc(\"total_revenue\")).limit(10))\n",
    "except Exception as e:\n",
    "    print(f\"\\n1. Brand/Category table not ready: {e}\")\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# 2. Location Performance\n",
    "try:\n",
    "    location_df = spark.table(gold_location_table)\n",
    "    print(f\"\\n2. Location Performance: {location_df.count()} records\")\n",
    "    display(location_df.orderBy(desc(\"total_revenue\")))\n",
    "except Exception as e:\n",
    "    print(f\"\\n2. Location table not ready: {e}\")\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# 3. Product Performance\n",
    "try:\n",
    "    product_df = spark.table(gold_product_table)\n",
    "    print(f\"\\n3. Product Performance: {product_df.count()} records\")\n",
    "    display(product_df.orderBy(desc(\"total_revenue\")).limit(10))\n",
    "except Exception as e:\n",
    "    print(f\"\\n3. Product table not ready: {e}\")\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# 4. Customer Insights\n",
    "try:\n",
    "    customer_df = spark.table(gold_customer_table)\n",
    "    print(f\"\\n4. Customer Insights: {customer_df.count()} records\")\n",
    "    \n",
    "    # Show by segment\n",
    "    print(\"\\nCustomers by Segment:\")\n",
    "    display(\n",
    "        customer_df.groupBy(\"customer_segment\")\n",
    "        .agg(\n",
    "            count(\"*\").alias(\"customer_count\"),\n",
    "            sum(\"total_spent\").alias(\"segment_revenue\"),\n",
    "            avg(\"order_count\").alias(\"avg_orders_per_customer\")\n",
    "        )\n",
    "        .orderBy(desc(\"segment_revenue\"))\n",
    "    )\n",
    "    \n",
    "    print(\"\\nTop 10 Customers:\")\n",
    "    display(customer_df.orderBy(desc(\"total_spent\")).limit(10))\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n4. Customer table not ready: {e}\")\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# 5. Daily Summary\n",
    "try:\n",
    "    daily_df = spark.table(gold_daily_summary_table)\n",
    "    print(f\"\\n5. Daily Summary: {daily_df.count()} records\")\n",
    "    \n",
    "    print(\"\\nDaily Revenue Trend:\")\n",
    "    display(\n",
    "        daily_df\n",
    "        .groupBy(\"day\")\n",
    "        .agg(\n",
    "            sum(\"daily_revenue\").alias(\"total_daily_revenue\"),\n",
    "            sum(\"order_count\").alias(\"total_orders\")\n",
    "        )\n",
    "        .orderBy(\"day\")\n",
    "    )\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n5. Daily Summary table not ready: {e}\")\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# MAGIC %md\n",
    "# MAGIC ## Real-Time Business Dashboard\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"REAL-TIME BUSINESS METRICS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "try:\n",
    "    # Overall metrics from brand/category table\n",
    "    overall = spark.sql(f\"\"\"\n",
    "        SELECT \n",
    "            SUM(order_count) as total_orders,\n",
    "            SUM(total_revenue) as total_revenue,\n",
    "            AVG(avg_order_value) as overall_avg_order_value,\n",
    "            SUM(unique_customers) as total_unique_customers,\n",
    "            SUM(total_discounts) as total_discounts_given\n",
    "        FROM {gold_brand_category_table}\n",
    "    \"\"\").first()\n",
    "    \n",
    "    print(f\"\\nüìä Current Business Metrics:\")\n",
    "    print(f\"  Total Orders: {overall['total_orders']:,}\")\n",
    "    print(f\"  Total Revenue: ${overall['total_revenue']:,.2f}\")\n",
    "    print(f\"  Avg Order Value: ${overall['overall_avg_order_value']:.2f}\")\n",
    "    print(f\"  Unique Customers: {overall['total_unique_customers']}\")\n",
    "    print(f\"  Total Discounts: ${overall['total_discounts_given']:,.2f}\")\n",
    "    \n",
    "    # Top performing categories\n",
    "    print(\"\\nüèÜ Top Performing Categories:\")\n",
    "    display(\n",
    "        spark.table(gold_brand_category_table)\n",
    "        .groupBy(\"category\")\n",
    "        .agg(sum(\"total_revenue\").alias(\"category_revenue\"))\n",
    "        .orderBy(desc(\"category_revenue\"))\n",
    "    )\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Dashboard not ready yet: {e}\")\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# MAGIC %md\n",
    "# MAGIC ## Stop All Gold Streams (Run when done)\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# Uncomment to stop all streams\n",
    "\"\"\"\n",
    "print(\"=\" * 70)\n",
    "print(\"STOPPING GOLD LAYER STREAMS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for stream in spark.streams.active:\n",
    "    print(f\"\\nStopping: {stream.id}\")\n",
    "    stream.stop()\n",
    "    print(f\"  ‚úì Stopped\")\n",
    "\n",
    "print(\"\\n‚úì All Gold streams stopped\")\n",
    "\"\"\"\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# MAGIC %md\n",
    "# MAGIC ## Summary\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"‚úì GOLD LAYER STREAMING SETUP COMPLETE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "try:\n",
    "    print(f\"\\nStreaming Gold Tables Created:\")\n",
    "    \n",
    "    tables_info = [\n",
    "        (gold_brand_category_table, \"Sales by Brand/Category\"),\n",
    "        (gold_location_table, \"Location Performance\"),\n",
    "        (gold_product_table, \"Product Performance\"),\n",
    "        (gold_customer_table, \"Customer Insights\"),\n",
    "        (gold_daily_summary_table, \"Daily Summary\")\n",
    "    ]\n",
    "    \n",
    "    for table, desc in tables_info:\n",
    "        try:\n",
    "            count = spark.table(table).count()\n",
    "            print(f\"  ‚úì {desc}: {count} records\")\n",
    "        except:\n",
    "            print(f\"  ‚è≥ {desc}: Processing...\")\n",
    "    \n",
    "    print(f\"\\nStreaming Status:\")\n",
    "    print(f\"  Active Queries: {len(spark.streams.active)}\")\n",
    "    \n",
    "    for stream in spark.streams.active:\n",
    "        print(f\"    - {stream.id}: {stream.status['message']}\")\n",
    "    \n",
    "    print(f\"\\nData Flow:\")\n",
    "    print(f\"  Silver Order Details (streaming)\")\n",
    "    print(f\"    ‚Üì Real-time aggregations\")\n",
    "    print(f\"  Gold Business Metrics\")\n",
    "    print(f\"    ‚Ä¢ Brand/Category sales\")\n",
    "    print(f\"    ‚Ä¢ Location performance\")\n",
    "    print(f\"    ‚Ä¢ Product analytics\")\n",
    "    print(f\"    ‚Ä¢ Customer segmentation\")\n",
    "    print(f\"    ‚Ä¢ Daily summaries\")\n",
    "    \n",
    "    print(f\"\\nKey Features:\")\n",
    "    print(f\"  ‚Ä¢ Watermarks for late data (10 min)\")\n",
    "    print(f\"  ‚Ä¢ Complete mode for full aggregations\")\n",
    "    print(f\"  ‚Ä¢ Append mode for time windows\")\n",
    "    print(f\"  ‚Ä¢ MERGE for customer updates\")\n",
    "    print(f\"  ‚Ä¢ Real-time business intelligence\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"Next Steps:\")\n",
    "    print(\"  1. Monitor streams with 'Monitor' cell\")\n",
    "    print(\"  2. Query tables for real-time analytics\")\n",
    "    print(\"  3. Build dashboards using Gold tables\")\n",
    "    print(\"  4. Stop streams when done\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ö†Ô∏è  Some tables not ready yet: {e}\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "gold",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
