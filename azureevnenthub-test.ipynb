{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f2f05294-c040-4b3b-bd8d-e8224ed1f753",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install azure-eventhub\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ff0f3205-3397-46bf-a812-e852391e9ceb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install --upgrade azure-eventhub\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0982d855-e99c-49eb-b668-e372760ba0c5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Import required Spark functions\n",
    "from pyspark.sql.functions import col, cast\n",
    "\n",
    "# --- 1. Configuration (Your provided logic) ---\n",
    "eventhub_namespace = \"evhns-natraining.servicebus.windows.net\"\n",
    "eventhub_name = \"evh-natraining-biju\"\n",
    "keyvault_scope = \"dbx-ss-kv-natraining-2\"\n",
    "secret_name = \"evh-natraining-read-write\"\n",
    "shared_access_key_name = \"SharedAccessKeyToSendAndListen\"\n",
    "\n",
    "secret_value = dbutils.secrets.get(scope=keyvault_scope, key=secret_name)\n",
    "\n",
    "connection_string = (\n",
    "    f\"Endpoint=sb://{eventhub_namespace}/;\"\n",
    "    f\"SharedAccessKeyName={shared_access_key_name};\"\n",
    "    f\"SharedAccessKey={secret_value};\" \n",
    "    f\"EntityPath={eventhub_name}\"\n",
    ")\n",
    "\n",
    "# --- 2. Event Hubs Setup (Native Connector) ---\n",
    "\n",
    "# The native connector requires the connection string to be encrypted\n",
    "eh_conf = {}\n",
    "eh_conf[\"eventhubs.connectionString\"] = connection_string\n",
    "\n",
    "# Optional: Define where to start reading\n",
    "# eh_conf[\"eventhubs.startingPosition\"] = \"@latest\"\n",
    "\n",
    "# --- 3. Read Stream ---\n",
    "\n",
    "df_stream = (spark.readStream\n",
    "  .format(\"eventhubs\")  # Uses the native connector, not Kafka  .option(\"spark.jars.packages\", \"com.microsoft.azure:azure-eventhubs-spark_2.12:2.3.18\")\n",
    "\n",
    "  .options(**eh_conf)\n",
    "  .load())\n",
    "\n",
    "# --- 4. Transform Data ---\n",
    "\n",
    "# In the native connector, the data payload is in the 'body' column as Binary\n",
    "# We cast it to String to make it readable.\n",
    "df_readable = df_stream.withColumn(\"body\", col(\"body\").cast(\"string\")) \\\n",
    "                       .select(\"body\", \"enqueuedTime\", \"offset\", \"partition\")\n",
    "\n",
    "# --- 5. Display or Write to Sink ---\n",
    "\n",
    "# Use display() to see the live stream in the notebook\n",
    "display(df_readable)\n",
    "\n",
    "# OR: Write to a Delta Table\n",
    "# df_readable.writeStream \\\n",
    "#   .format(\"delta\") \\\n",
    "#   .outputMode(\"append\") \\\n",
    "#   .option(\"checkpointLocation\", \"/mnt/telemetry/checkpoints/evh_raw\") \\\n",
    "#   .start(\"/mnt/telemetry/tables/evh_raw_data\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "azureevnenthub-test",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
