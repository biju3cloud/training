{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "333fb534-f840-4c33-bacb-113135a68042",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ./02config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6509b2f9-61a7-424a-a5c2-608b23f047c1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Databricks notebook source\n",
    "# MAGIC %md\n",
    "# MAGIC # Silver Layer - Streaming Join Orders with Products\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# MAGIC %run ./02config\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# MAGIC %md\n",
    "# MAGIC ## Read Bronze Streams\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"READING BRONZE STREAMS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Read streaming orders with watermark\n",
    "orders_stream = (spark.readStream\n",
    "    .format(\"delta\")\n",
    "    .table(bronze_orders_table)\n",
    "    .withWatermark(\"bronze_timestamp\", \"1 minute\")\n",
    ")\n",
    "\n",
    "print(f\"‚úì Orders stream: {bronze_orders_table}\")\n",
    "\n",
    "# Read products as static (more efficient for small dimension)\n",
    "products_df = spark.read.format(\"delta\").table(bronze_products_table)\n",
    "\n",
    "print(f\"‚úì Products static: {bronze_products_table} ({products_df.count()} records)\")\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# MAGIC %md\n",
    "# MAGIC ## Streaming Join and Enrichment\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"CONFIGURING JOIN\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "order_details_stream = (orders_stream\n",
    "    .join(products_df, on=\"product_id\", how=\"left\")\n",
    "    .select(\n",
    "        # Order fields\n",
    "        orders_stream.order_id,\n",
    "        orders_stream.customer_id,\n",
    "        orders_stream.customer_name,\n",
    "        orders_stream.location,\n",
    "        orders_stream.order_status,\n",
    "        orders_stream.payment_method,\n",
    "        orders_stream.quantity,\n",
    "        orders_stream.discount_pct,\n",
    "        orders_stream.total_amount,\n",
    "        \n",
    "        # Order timestamp\n",
    "        when(col(\"order_timestamp_parsed\").isNotNull(), \n",
    "             col(\"order_timestamp_parsed\"))\n",
    "        .otherwise(to_timestamp(orders_stream.order_timestamp))\n",
    "        .alias(\"order_timestamp\"),\n",
    "        \n",
    "        # Product fields\n",
    "        products_df.product_id.alias(\"product_id_joined\"),\n",
    "        products_df.product_name,\n",
    "        products_df.category,\n",
    "        products_df.brand,\n",
    "        products_df.base_price,\n",
    "        products_df.unit_price,\n",
    "        \n",
    "        # Metadata\n",
    "        orders_stream.event_time,\n",
    "        orders_stream.eventhub_offset,\n",
    "        orders_stream.sequence_number,\n",
    "        orders_stream.partition_id,\n",
    "        orders_stream.bronze_timestamp\n",
    "    )\n",
    "    # Calculated fields\n",
    "    .withColumn(\"order_date\", to_date(col(\"order_timestamp\")))\n",
    "    .withColumn(\"order_hour\", hour(col(\"order_timestamp\")))\n",
    "    .withColumn(\"day_of_week\", dayofweek(col(\"order_timestamp\")))\n",
    "    .withColumn(\"line_total\", col(\"quantity\") * col(\"unit_price\"))\n",
    "    .withColumn(\"discount_amount\", \n",
    "                col(\"total_amount\") - (col(\"quantity\") * col(\"unit_price\")))\n",
    "    .withColumn(\"silver_timestamp\", current_timestamp())\n",
    "    .drop(\"product_id_joined\")\n",
    ")\n",
    "\n",
    "print(\"‚úì Join configured (LEFT JOIN on product_id)\")\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# MAGIC %md\n",
    "# MAGIC ## Add Data Quality Checks\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "order_details_stream_with_quality = (order_details_stream\n",
    "    .withColumn(\"has_product_info\", col(\"product_name\").isNotNull())\n",
    "    .withColumn(\"is_valid_quantity\", col(\"quantity\") > 0)\n",
    "    .withColumn(\"is_valid_amount\", col(\"total_amount\") > 0)\n",
    "    .withColumn(\"data_quality_score\", \n",
    "                (col(\"has_product_info\").cast(\"int\") + \n",
    "                 col(\"is_valid_quantity\").cast(\"int\") + \n",
    "                 col(\"is_valid_amount\").cast(\"int\")))\n",
    ")\n",
    "\n",
    "print(\"‚úì Data quality checks added\")\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# MAGIC %md\n",
    "# MAGIC ## Write to Silver Table\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STARTING SILVER STREAM\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "silver_query = (order_details_stream_with_quality\n",
    "    .writeStream\n",
    "    .format(\"delta\")\n",
    "    .outputMode(\"append\")\n",
    "    .option(\"checkpointLocation\", silver_checkpoint)\n",
    "    .option(\"mergeSchema\", \"true\")\n",
    "    #.trigger(processingTime=\"15 seconds\")\n",
    "    .trigger(availableNow=True)\n",
    "    .toTable(silver_table)\n",
    ")\n",
    "\n",
    "print(f\"‚úì Silver stream started: {silver_query.id}\")\n",
    "print(f\"  Target: {silver_table}\")\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# MAGIC %md\n",
    "# MAGIC ## Monitor Stream\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ACTIVE STREAMS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for stream in spark.streams.active:\n",
    "    print(f\"\\nQuery ID: {stream.id}\")\n",
    "    print(f\"  Status: {stream.status['message']}\")\n",
    "    print(f\"  Active: {stream.isActive}\")\n",
    "    \n",
    "    if stream.recentProgress:\n",
    "        latest = stream.recentProgress[-1]\n",
    "        print(f\"  Batch: {latest.get('batchId', 'N/A')}\")\n",
    "        print(f\"  Input Rows: {latest.get('numInputRows', 0)}\")\n",
    "        print(f\"  Rate: {latest.get('processedRowsPerSecond', 0):.2f} rows/sec\")\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# MAGIC %md\n",
    "# MAGIC ## Monitor Data Quality\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "import time\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"MONITORING (30 seconds)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for i in range(6):\n",
    "    time.sleep(5)\n",
    "    \n",
    "    try:\n",
    "        silver_count = spark.table(silver_table).count()\n",
    "        \n",
    "        quality_stats = spark.sql(f\"\"\"\n",
    "            SELECT \n",
    "                COUNT(*) as total,\n",
    "                SUM(CASE WHEN has_product_info THEN 1 ELSE 0 END) as complete,\n",
    "                AVG(data_quality_score) as avg_score\n",
    "            FROM {silver_table}\n",
    "        \"\"\").first()\n",
    "        \n",
    "        print(f\"‚è±Ô∏è  {(i+1)*5}s - Records: {silver_count:,} | Complete: {quality_stats['complete']} | Score: {quality_stats['avg_score']:.2f}/3.0\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚è±Ô∏è  {(i+1)*5}s - Waiting for data...\")\n",
    "\n",
    "print(\"\\n‚úì Monitoring complete\")\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# MAGIC %md\n",
    "# MAGIC ## Verify Silver Table\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"SILVER VERIFICATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "try:\n",
    "    silver_df = spark.table(silver_table)\n",
    "    total_records = silver_df.count()\n",
    "    \n",
    "    print(f\"\\nüìä Silver Table: {total_records:,} records\")\n",
    "    \n",
    "    if total_records > 0:\n",
    "        # Data quality\n",
    "        quality_df = silver_df.groupBy(\"has_product_info\").count().collect()\n",
    "        for row in quality_df:\n",
    "            status = \"‚úì Complete\" if row['has_product_info'] else \"‚ö†Ô∏è Missing Product\"\n",
    "            print(f\"  {status}: {row['count']:,}\")\n",
    "        \n",
    "        # Latest orders\n",
    "        print(\"\\n‚úì Latest enriched orders:\")\n",
    "        display(\n",
    "            silver_df\n",
    "            .select(\"order_id\", \"customer_name\", \"location\", \"product_name\", \"brand\", \n",
    "                    \"category\", \"quantity\", \"unit_price\", \"total_amount\", \"order_timestamp\",\n",
    "                    \"data_quality_score\")\n",
    "            .orderBy(desc(\"silver_timestamp\"))\n",
    "            .limit(10)\n",
    "        )\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è  Table not available: {e}\")\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# MAGIC %md\n",
    "# MAGIC ## Analysis Queries\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "try:\n",
    "    silver_df = spark.table(silver_table)\n",
    "    \n",
    "    # Orders by Brand\n",
    "    print(\"\\n1. Orders by Brand:\")\n",
    "    display(\n",
    "        silver_df\n",
    "        .groupBy(\"brand\")\n",
    "        .agg(\n",
    "            count(\"*\").alias(\"orders\"),\n",
    "            sum(\"total_amount\").alias(\"revenue\"),\n",
    "            avg(\"total_amount\").alias(\"avg_order\")\n",
    "        )\n",
    "        .orderBy(desc(\"revenue\"))\n",
    "    )\n",
    "    \n",
    "    # Orders by Category\n",
    "    print(\"\\n2. Orders by Category:\")\n",
    "    display(\n",
    "        silver_df\n",
    "        .groupBy(\"category\")\n",
    "        .agg(\n",
    "            count(\"*\").alias(\"orders\"),\n",
    "            sum(\"total_amount\").alias(\"revenue\"),\n",
    "            sum(\"quantity\").alias(\"quantity\")\n",
    "        )\n",
    "        .orderBy(desc(\"revenue\"))\n",
    "    )\n",
    "    \n",
    "    # Top Customers\n",
    "    print(\"\\n3. Top Customers:\")\n",
    "    display(\n",
    "        silver_df\n",
    "        .groupBy(\"customer_id\", \"customer_name\", \"location\")\n",
    "        .agg(\n",
    "            count(\"*\").alias(\"orders\"),\n",
    "            sum(\"total_amount\").alias(\"total_spent\"),\n",
    "            avg(\"total_amount\").alias(\"avg_order\")\n",
    "        )\n",
    "        .orderBy(desc(\"total_spent\"))\n",
    "        .limit(20)\n",
    "    )\n",
    "    \n",
    "    # Hourly Trends\n",
    "    print(\"\\n4. Hourly Trends:\")\n",
    "    display(\n",
    "        silver_df\n",
    "        .groupBy(\"order_hour\")\n",
    "        .agg(\n",
    "            count(\"*\").alias(\"orders\"),\n",
    "            sum(\"total_amount\").alias(\"revenue\")\n",
    "        )\n",
    "        .orderBy(\"order_hour\")\n",
    "    )\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Analysis not available: {e}\")\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# MAGIC %md\n",
    "# MAGIC ## Dashboard View\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "spark.sql(f\"\"\"\n",
    "CREATE OR REPLACE TEMP VIEW silver_dashboard AS\n",
    "SELECT \n",
    "    order_date,\n",
    "    order_hour,\n",
    "    category,\n",
    "    brand,\n",
    "    location,\n",
    "    COUNT(*) as order_count,\n",
    "    SUM(total_amount) as revenue,\n",
    "    AVG(total_amount) as avg_order_value,\n",
    "    SUM(quantity) as total_items,\n",
    "    MAX(silver_timestamp) as last_updated\n",
    "FROM {silver_table}\n",
    "GROUP BY order_date, order_hour, category, brand, location\n",
    "\"\"\")\n",
    "\n",
    "print(\"‚úì Dashboard view created\")\n",
    "\n",
    "# Today's performance\n",
    "print(\"\\nToday's Performance:\")\n",
    "display(spark.sql(\"\"\"\n",
    "SELECT \n",
    "    category,\n",
    "    brand,\n",
    "    SUM(order_count) as orders,\n",
    "    SUM(revenue) as revenue,\n",
    "    MAX(last_updated) as last_update\n",
    "FROM silver_dashboard\n",
    "WHERE order_date = CURRENT_DATE()\n",
    "GROUP BY category, brand\n",
    "ORDER BY revenue DESC\n",
    "\"\"\"))\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# MAGIC %md\n",
    "# MAGIC ## Stop Streams\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# Uncomment to stop\n",
    "\"\"\"\n",
    "for stream in spark.streams.active:\n",
    "    print(f\"Stopping: {stream.id}\")\n",
    "    stream.stop()\n",
    "print(\"‚úì Streams stopped\")\n",
    "\"\"\"\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# MAGIC %md\n",
    "# MAGIC ## Summary\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"SILVER LAYER COMPLETE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "try:\n",
    "    orders_count = spark.table(bronze_orders_table).count()\n",
    "    products_count = spark.table(bronze_products_table).count()\n",
    "    silver_count = spark.table(silver_table).count()\n",
    "    \n",
    "    quality_check = spark.sql(f\"\"\"\n",
    "        SELECT \n",
    "            COUNT(*) as total,\n",
    "            SUM(CASE WHEN has_product_info THEN 1 ELSE 0 END) as complete,\n",
    "            SUM(CASE WHEN NOT has_product_info THEN 1 ELSE 0 END) as incomplete\n",
    "        FROM {silver_table}\n",
    "    \"\"\").first()\n",
    "    \n",
    "    print(f\"\\nRecords:\")\n",
    "    print(f\"  Bronze Orders: {orders_count:,}\")\n",
    "    print(f\"  Bronze Products: {products_count:,}\")\n",
    "    print(f\"  Silver Details: {silver_count:,}\")\n",
    "    \n",
    "    if quality_check:\n",
    "        success_rate = (quality_check['complete'] / quality_check['total'] * 100) if quality_check['total'] > 0 else 0\n",
    "        print(f\"\\nData Quality:\")\n",
    "        print(f\"  Complete: {quality_check['complete']:,}\")\n",
    "        print(f\"  Incomplete: {quality_check['incomplete']:,}\")\n",
    "        print(f\"  Success Rate: {success_rate:.1f}%\")\n",
    "    \n",
    "    print(f\"\\nActive Streams: {len(spark.streams.active)}\")\n",
    "    for stream in spark.streams.active:\n",
    "        print(f\"  ‚Ä¢ {stream.id}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è  Tables not ready yet\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "04silver",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
