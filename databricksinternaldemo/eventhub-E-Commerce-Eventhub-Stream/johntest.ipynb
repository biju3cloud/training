{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4955dbda-2e06-4178-8c54-fabaee01dbca",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install azure-eventhub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f8478527-f844-4a48-860f-1afb4ffbefad",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Databricks notebook source\n",
    "# DBTITLE 1,Add/Define Widgets\n",
    "# Option A - define the eventhub name\n",
    "dbutils.widgets.text(\"eventhub_name\", \"evh-natraining-john\")\n",
    "EVENTHUB_NAME = dbutils.widgets.get(\"eventhub_name\")\n",
    "\n",
    "# define the access key and pass the eventhub name to the connection string var\n",
    "secret_value = dbutils.secrets.get(\n",
    "    scope=\"dbx-ss-kv-natraining-2\", key=\"evh-natraining-read-write\"\n",
    ")\n",
    "send_conn_str = (\n",
    "    \"Endpoint=sb://evhns-natraining.servicebus.windows.net/;\"\n",
    "    \"SharedAccessKeyName=SharedAccessKeyToSendAndListen;\"\n",
    "    f\"SharedAccessKey={secret_value};\"\n",
    "    f\"EntityPath={EVENTHUB_NAME}\"\n",
    ")\n",
    "\n",
    "# define the test message via widget and connection string var\n",
    "dbutils.widgets.text(\n",
    "    \"test_message\", \"Hello from John Rice on Databricks!\",\n",
    ")\n",
    "EVENTHUB_CONN_STR = send_conn_str\n",
    "\n",
    "TEST_MESSAGE = dbutils.widgets.get(\"test_message\")\n",
    "\n",
    "# fail if not exists\n",
    "if not EVENTHUB_CONN_STR or not EVENTHUB_NAME:\n",
    "    raise ValueError(\n",
    "        \"Please provide both 'eventhub_connection_string' and 'eventhub_name' via widgets.\"\n",
    "    )\n",
    "\n",
    "# explicitly inform user of param load\n",
    "print(\"Parameters loaded. Ready to send a test message.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "936b19a8-7876-4058-bd2d-0b30dd1e08b1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Option B (prod-style): use Databricks secrets instead of widgets\n",
    "#\n",
    "#\n",
    "# EVENTHUB_CONN_STR = dbutils.secrets.get(\"azure-kv-scope\", \"eventhub-connstr\")\n",
    "# EVENTHUB_NAME = \"my-eventhub\"\n",
    "# TEST_MESSAGE = \"Hello from Databricks via secret!\"\n",
    "# -------------------------------------------------------------------\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# DBTITLE 1,Send Event\n",
    "from azure.eventhub import EventHubProducerClient, EventData\n",
    "import json\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "\n",
    "def send_test_event(message: str) -> None:\n",
    "    \"\"\"Send a single test event and raise a clear error if anything fails.\"\"\"\n",
    "    producer = EventHubProducerClient.from_connection_string(\n",
    "        conn_str=EVENTHUB_CONN_STR,\n",
    "        eventhub_name=EVENTHUB_NAME,\n",
    "    )\n",
    "\n",
    "    payload = {\n",
    "        \"message\": message,\n",
    "        \"source\": \"databricks-notebook-smoketest\",\n",
    "        \"timestamp_utc\": datetime.now(timezone.utc).isoformat(timespec=\"milliseconds\"),\n",
    "    }\n",
    "\n",
    "    body = json.dumps(payload)\n",
    "\n",
    "    with producer:\n",
    "        batch = producer.create_batch()\n",
    "        batch.add(EventData(body))\n",
    "        producer.send_batch(batch)\n",
    "\n",
    "    print(f\"âœ… Sent test event: {body}\")\n",
    "\n",
    "\n",
    "# Example usage for the course:\n",
    "send_test_event(TEST_MESSAGE)\n",
    "\n",
    "# COMMAND ----------\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dc2d79fd-8a52-4615-9236-a0e30f5eb88f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# MAGIC %md\n",
    "# MAGIC # Let's read from the EventHub using Spark Streaming!\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "EVENTHUB_NAME = dbutils.widgets.get(\"eventhub_name\")\n",
    "\n",
    "EVENTHUB_CONN_STR = (\n",
    "    \"Endpoint=sb://evhns-natraining.servicebus.windows.net/;\"\n",
    "    \"SharedAccessKeyName=SharedAccessKeyToSendAndListen;\"\n",
    "    f\"SharedAccessKey={secret_value};\"\n",
    "    f\"EntityPath={EVENTHUB_NAME}\"\n",
    ").strip().replace(\"\\n\", \"\").replace(\"\\r\", \"\")\n",
    "\n",
    "encrypted_conn_str = spark._jvm.org.apache.spark.eventhubs.EventHubsUtils.encrypt(EVENTHUB_CONN_STR)\n",
    "\n",
    "event_hubs_conf = {\n",
    "    \"eventhubs.connectionString\": encrypted_conn_str,\n",
    "    \"eventhubs.consumerGroup\": \"$Default\",\n",
    "    \"eventhubs.startingPosition\": \"\"\"{\n",
    "      \"offset\":\"-1\",\n",
    "      \"seqNo\":-1,\n",
    "      \"enqueuedTime\":\"1970-01-01T00:00:00.000Z\",\n",
    "      \"isInclusive\":false\n",
    "    }\"\"\"\n",
    "}\n",
    "\n",
    "\n",
    "print(\"Event Hub read configuration ready:\", EVENTHUB_NAME)\n",
    "\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# Databricks notebook cell: 06_read_stream\n",
    "\n",
    "raw_stream_df = (\n",
    "    spark.readStream\n",
    "         .format(\"eventhubs\")\n",
    "         .options(**event_hubs_conf)\n",
    "         .load()\n",
    ")\n",
    "\n",
    "display(raw_stream_df)\n",
    "\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# Databricks notebook cell: 07_parse_body\n",
    "\n",
    "from pyspark.sql.functions import col, from_json\n",
    "from pyspark.sql.types import StructType, StructField, StringType\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"message\", StringType()),\n",
    "    StructField(\"source\", StringType()),\n",
    "    StructField(\"timestamp_utc\", StringType()),\n",
    "])\n",
    "\n",
    "parsed_df = (\n",
    "    raw_stream_df\n",
    "        .selectExpr(\"CAST(body AS STRING) AS body_str\")\n",
    "        .select(from_json(col(\"body_str\"), schema).alias(\"data\"))\n",
    "        .select(\"data.*\")\n",
    ")\n",
    "\n",
    "display(parsed_df)\n",
    "\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# Databricks notebook cell: 08_console_sink\n",
    "\n",
    "query = (\n",
    "    parsed_df\n",
    "        .writeStream\n",
    "        .format(\"console\")\n",
    "        .outputMode(\"append\")\n",
    "        .start()\n",
    ")\n",
    "\n",
    "query.awaitTermination()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "56dca7f1-6ea7-4a65-bd47-37b07952d493",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "connectionString = \"Endpoint=sb://evhns-natraining.servicebus.windows.net/;SharedAccessKeyName=...;SharedAccessKey=...;EntityPath=evh-natraining-john\"\n",
    "\n",
    "ehConf = {\n",
    "  'eventhubs.connectionString': sc._jvm.org.apache.spark.eventhubs.EventHubsUtils.encrypt(connectionString),\n",
    "  'eventhubs.consumerGroup': f'$Default',  # Unique per cluster\n",
    "  'eventhubs.startingPosition': json.dumps({\"offset\": \"-1\", \"seqNo\": -1}),\n",
    "  'eventhubs.maxEventsPerTrigger': 1000\n",
    "}\n",
    "\n",
    "df = spark.readStream.format(\"eventhubs\").options(**ehConf).load()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": -1,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "johntest",
   "widgets": {
    "eventhub_name": {
     "currentValue": "evh-natraining-john",
     "nuid": "84049193-d2b1-4dbf-a256-f2dcf5c99b23",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "evh-natraining-john",
      "label": null,
      "name": "eventhub_name",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "evh-natraining-john",
      "label": null,
      "name": "eventhub_name",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "test_message": {
     "currentValue": "Hello from biju on Databricks!",
     "nuid": "e9e218fb-ed81-4ebd-b335-667af0011d89",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "Hello from John Rice on Databricks!",
      "label": null,
      "name": "test_message",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "Hello from John Rice on Databricks!",
      "label": null,
      "name": "test_message",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    }
   }
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
