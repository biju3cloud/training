{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d70bfcb9-8ed6-4a1a-87e7-e9df164cffa1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Variables from your configuration\n",
    "eh_namespace = \"evhns-natraining.servicebus.windows.net\"\n",
    "eh_name = \"evh-natraining-biju\"\n",
    "keyvault_scope = \"dbx-ss-kv-natraining-2\"\n",
    "secret_name = \"evh-natraining-read-write\"\n",
    "shared_access_key_name = \"SharedAccessKeyToSendAndListen\"\n",
    "\n",
    "# Retrieve the secret (Primary Key) from Databricks Secret Scope\n",
    "shared_access_key = dbutils.secrets.get(scope=keyvault_scope, key=secret_name)\n",
    "\n",
    "# Construct the Connection String\n",
    "# Note: Kafka authentication in Event Hubs uses this specific format for the password\n",
    "connection_string = f\"Endpoint=sb://{eh_namespace}/;SharedAccessKeyName={shared_access_key_name};SharedAccessKey={shared_access_key};EntityPath={eh_name}\"\n",
    "\n",
    "# Variables from your configuration\n",
    "eh_namespace = \"evhns-natraining.servicebus.windows.net\"\n",
    "eh_name = \"evh-natraining-biju\"\n",
    "keyvault_scope = \"dbx-ss-kv-natraining-2\"\n",
    "secret_name = \"evh-natraining-read-write\"\n",
    "shared_access_key_name = \"SharedAccessKeyToSendAndListen\"\n",
    "\n",
    "# Retrieve the secret (Primary Key) from Databricks Secret Scope\n",
    "shared_access_key = dbutils.secrets.get(scope=keyvault_scope, key=secret_name)\n",
    "\n",
    "# Construct the Connection String\n",
    "# Note: Kafka authentication in Event Hubs uses this specific format for the password\n",
    "connection_string = f\"Endpoint=sb://{eh_namespace}/;SharedAccessKeyName={shared_access_key_name};SharedAccessKey={shared_access_key};EntityPath={eh_name}\"\n",
    "\n",
    "\n",
    "try:\n",
    "    secret_value = dbutils.secrets.get(scope=keyvault_scope, key=secret_name)\n",
    "    print(\"✓ Successfully retrieved secret from Key Vault\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ Error retrieving secret: {str(e)}\")\n",
    "    raise\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# MAGIC %md\n",
    "# MAGIC ## Build Connection String and Kafka Options\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# Connection string\n",
    "connection_string = (\n",
    "    f\"Endpoint=sb://{eh_namespace}/;\"\n",
    "    f\"SharedAccessKeyName={shared_access_key_name};\"\n",
    "    f\"SharedAccessKey={secret_value}\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "023caa20-6b4d-474f-b681-623e336a2bdc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "KAFKA_OPTIONS = {\n",
    "    \"kafka.bootstrap.servers\": f\"{eh_namespace}:9093\",\n",
    "    \"subscribe\": eh_name,\n",
    "    \"kafka.sasl.mechanism\": \"PLAIN\",\n",
    "    \"kafka.security.protocol\": \"SASL_SSL\",\n",
    "    \"kafka.sasl.jaas.config\": f'kafkashaded.org.apache.kafka.common.security.plain.PlainLoginModule required username=\"$ConnectionString\" password=\"{connection_string}\";',\n",
    "    \"kafka.request.timeout.ms\": \"60000\",\n",
    "    \"kafka.session.timeout.ms\": \"30000\",\n",
    "    \"failOnDataLoss\": \"false\",\n",
    "    \"startingOffsets\": \"latest\",\n",
    "    \"maxOffsetsPerTrigger\": \"10000\"  # Process 10k records per batch\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8385568d-5f0a-4283-aab4-65ca102ca842",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Read the stream\n",
    "df_stream = (spark.readStream\n",
    "             .format(\"kafka\")\n",
    "             .options(**KAFKA_OPTIONS)\n",
    "             .load())\n",
    "\n",
    "# Convert binary 'value' to String for preview\n",
    "df_decoded = df_stream.withColumn(\"body\", col(\"value\").cast(\"string\"))\n",
    "\n",
    "# Display the stream in the notebook\n",
    "display(df_decoded.select(\"offset\", \"timestamp\", \"body\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d0dae93b-a293-4c1e-a1f3-3d322b06431a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Read the stream\n",
    "df_stream = (spark.readStream\n",
    "             .format(\"kafka\")\n",
    "             .options(**{'kafka.bootstrap.servers': 'localhost:9092', 'subscribe': 'topic_name'})\n",
    "             .load())\n",
    "\n",
    "# Convert binary 'value' to String for preview\n",
    "df_decoded = df_stream.withColumn(\"body\", col(\"value\").cast(\"string\"))\n",
    "\n",
    "# Display the stream in the notebook\n",
    "display(df_decoded.select(\"offset\", \"timestamp\", \"body\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "70ecb6ee-cb53-486b-b627-db7f70174587",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\"evhns-natraining.servicebus.windows.net\"https://evhns-natraining.servicebus.windows.net:443/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7b7476e3-d207-451d-8679-1446dc22a79a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "  %sh nc -vz evhns-natraining.servicebus.windows.net 9093"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1c3e1c4e-09ab-4dc4-b9b2-9603dc8628db",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sh nslookup evhns-natraining.servicebus.windows.net\n",
    "%sh nc -vz evhns-natraining.servicebus.windows.net 9093"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "10915196-c16a-481d-b2ae-a4448d201269",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sh\n",
    "nc -vz evhns-natraining.servicebus.windows.net 9093\n",
    "echo \"nc exit code: $?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ff10a220-6179-4bf9-ac13-497a0e0f62a2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "eh_namespace = \"evhns-natraining.servicebus.windows.net\"\n",
    "eh_name = \"evh-natraining-biju\"\n",
    "keyvault_scope = \"dbx-ss-kv-natraining-2\"\n",
    "secret_name = \"evh-natraining-read-write\"\n",
    "shared_access_key_name = \"SharedAccessKeyToSendAndListen\"\n",
    "\n",
    "secret_value = dbutils.secrets.get(scope=keyvault_scope, key=secret_name)\n",
    "\n",
    "connection_string = (\n",
    "    f\"Endpoint=sb://{eh_namespace}/;\"\n",
    "    f\"SharedAccessKeyName={shared_access_key_name};\"\n",
    "    f\"SharedAccessKey={secret_value};\"\n",
    "    f\"EntityPath={eh_name}\"\n",
    ")\n",
    "\n",
    "KAFKA_OPTIONS = {\n",
    "    \"kafka.bootstrap.servers\": f\"{eh_namespace}:9093\",\n",
    "    \"subscribe\": eh_name,\n",
    "    \"kafka.sasl.mechanism\": \"PLAIN\",\n",
    "    \"kafka.security.protocol\": \"SASL_SSL\",\n",
    "    \"kafka.sasl.jaas.config\": (\n",
    "        f'kafkashaded.org.apache.kafka.common.security.plain.PlainLoginModule '\n",
    "        f'required username=\"$ConnectionString\" password=\"{connection_string}\";'\n",
    "    ),\n",
    "    \"kafka.request.timeout.ms\": \"120000\",\n",
    "    \"kafka.session.timeout.ms\": \"30000\",\n",
    "    \"failOnDataLoss\": \"false\",\n",
    "    \"startingOffsets\": \"latest\",\n",
    "    \"maxOffsetsPerTrigger\": \"10000\",\n",
    "}\n",
    "\n",
    "df_stream = (\n",
    "    spark.readStream\n",
    "         .format(\"kafka\")\n",
    "         .options(**KAFKA_OPTIONS)\n",
    "         .load()\n",
    ")\n",
    "\n",
    "display(df_stream.select(col(\"offset\"), col(\"timestamp\"), col(\"value\").cast(\"string\")))"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 8946049318739263,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "kafkatest",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
